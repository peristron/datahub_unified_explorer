ğŸ”— Brightspace Dataset Explorer

A Unified Schema Intelligence Engine for D2L/Brightspace Data Hub

    Status: Production Ready (v2.2)
    Built With: Streamlit, Pandas, NetworkX, Plotly, BeautifulSoup

This application acts as a "Rosetta Stone" for Data Engineers, Analysts, and LMS Administrators working with Brightspace Data Sets (BDS). It bridges the gap between raw Knowledge Base documentation and actionable SQL/Python code, providing a visual, interactive way to explore the complex Entity-Relationship model of the LMS.
ğŸš€ Key Features
1. ğŸ›ï¸ Experience Modes

    ğŸŸ¢ Quick Explorer: A streamlined interface for general users. Focuses on the Dashboard, Visual Map, and AI Assistant
    ğŸ”· Power User: Unlocks the full engineering toolkit, including the SQL Builder, Schema Browser, KPI Recipes, and UDF Flattener

2. ğŸ“‹ Schema Browser & Comparison

    Context Aware: Automatically scrapes and summarizes the "Context Description" from D2L documentation (e.g., explaining what a dataset represents, not just its columns)
    Side-by-Side Comparison: Select multiple datasets simultaneously to verify column consistency (e.g., checking UserId formats across Users and Enrollments)
    Decoder Ring: Automatically detects and decodes integer Enums (e.g., GradeObjectTypeId: 1 = Numeric) using built-in mappings

3. ğŸ›¤ï¸ Advanced Path Finder

    Multi-Path Logic: Unlike standard tools that only show one path, this engine calculates all valid join paths (up to 4 hops) between two datasets
    Ranked Results: Displays the top 5 shortest paths, helping you distinguish between a direct join and an indirect relationship via a "Bridge" table

4. ğŸ—ºï¸ Interactive Relationship Map

    Visualize the Invisible: See how tables connect via Primary and Foreign Keys (PK/FK)
    Modes:
        Network Graph: Force-directed graph showing direct connections
        Solar System: "Category" suns with dataset planets (excellent for discovery)
        Heatmap: Density matrix of connections
    Export: Download high-res PNGs or GraphViz (DOT) files for external diagramming tools (Visio/LucidChart)

5. âš¡ Query Builder (Polyglot)

    Automated Joins: Select 2+ datasets, and the engine calculates the join logic
    Output Formats:
        SQL: Generates LEFT JOIN syntax for T-SQL, Snowflake, or PostgreSQL
        Python: Generates pandas.merge() code for data scientists working with CSV exports

6. ğŸ”§ UDF Flattener

    The Problem: D2L stores custom user data (e.g., Pronouns, Dept ID) in difficult-to-query EAV (Entity-Attribute-Value) tables
    The Solution: Generates the complex MAX(CASE WHEN...) SQL required to pivot these rows into clean, horizontal columns

7. ğŸ¤– AI Data Architect

    Context-Aware: Sends schema metadata (column names/types) to LLMs (OpenAI/xAI) to answer natural language questions
    Secure: No actual row data ever leaves the application

ğŸ› ï¸ Setup & Installation

Prerequisites: Python 3.9+

    Clone the repository:

Bash

git clone https://github.com/your-org/brightspace-dataset-explorer.git
cd brightspace-dataset-explorer

Install dependencies:

Bash

pip install -r requirements.txt

Configure Secrets:
Create a file at .streamlit/secrets.toml:

toml

# Password to unlock AI features
app_password = "your_secure_password"

# API Keys (Optional - can be entered in UI)
openai_api_key = "sk-..."
xai_api_key = "..."

Run the App:

Bash

    streamlit run unified_dataset_explorer.py

ğŸš¦ First Run / Initialization

Important: When you launch the application for the first time, it will be empty because no schema metadata has been loaded yet

    Open the Sidebar on the left.
    Expand the âš™ï¸ Data Management section.
    Click the "ğŸ”„ Scrape & Update All URLs" button.
    Wait approx. 30 seconds for the scraper to fetch definitions and context summaries from the D2L Knowledge Base.
    Once complete, the dashboard will populate, and you can begin exploring.

ğŸ“‚ File Structure

    unified_dataset_explorer.py: The main application monolith (optimized for Streamlit Cloud deployment).
    dataset_metadata.csv: The cached schema definitions (generated by the internal scraper).
    requirements.txt: Python package dependencies.

âš ï¸ Limitations

    Metadata Only: This tool operates on the documentation of the datasets, not your live database. It cannot preview rows of data.
    Standard Schema: Custom columns created by your SIS integration (e.g., Oracle_ID_Custom) will not appear here, as they are not present in the public D2L Knowledge Base.
    Manual Field IDs: For the UDF Flattener, you must manually input your specific Field IDs (e.g., 4, 9) because the scraper cannot access your private configuration values.

Open Source software licensed under the MIT License.
